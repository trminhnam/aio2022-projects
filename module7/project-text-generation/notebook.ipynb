{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 20000\n",
    "MAX_SEQ_LEN = 80\n",
    "\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 3e-5\n",
    "\n",
    "EMBEDDING_DIM = 256\n",
    "N_HEADS = 8\n",
    "FF_DIM = 256\n",
    "N_LAYERS = 1\n",
    "DROP_OUT = 0.1\n",
    "\n",
    "DATASET_DIR = 'aclImdb'\n",
    "TRAIN_DIR = os.path.join(DATASET_DIR, 'train')\n",
    "TEST_DIR = os.path.join(DATASET_DIR, 'test')\n",
    "CLASSES = ['neg', 'pos']\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and custom tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 50000\n"
     ]
    }
   ],
   "source": [
    "file_path = []\n",
    "for SUBSET_DIR in [TRAIN_DIR, TEST_DIR]:\n",
    "    for CLASS in CLASSES:\n",
    "        CLASS_DIR = os.path.join(SUBSET_DIR, CLASS)\n",
    "        for filename in os.listdir(CLASS_DIR):\n",
    "            file_path.append(os.path.join(CLASS_DIR, filename))\n",
    "\n",
    "print(f'Number of text files: {len(file_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    \"\"\"Remove html tags from a string\n",
    "    Reference: https://stackoverflow.com/a/9662362\n",
    "\n",
    "    Args:\n",
    "        text (str): input string/document\n",
    "\n",
    "    Returns:\n",
    "        str: string without html tags\n",
    "        \n",
    "    \"\"\"\n",
    "    TAG_RE = re.compile(r'<[^>]+>')\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "def standardization(text):\n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # remove newline\n",
    "    text = text.replace('\\n', ' ').replace('\\r', '')\n",
    "    \n",
    "    # remove html tags\n",
    "    text = remove_html_tags(text)\n",
    "    \n",
    "    # remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # remove extra spaces\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTokenizer:\n",
    "    def __init__(self, vocab_size, max_seq_len):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.vocab = {}\n",
    "        self.reverse_vocab = {}\n",
    "        self.index = 0\n",
    "        self.__init_special_tokens()\n",
    "        \n",
    "        print(self.vocab)\n",
    "        print(self.reverse_vocab)\n",
    "    \n",
    "    def __init_special_tokens(self):\n",
    "        special_tokens = ['<PAD>', '<UNK>', '<SOS>', '<EOS>']\n",
    "        for token in special_tokens:\n",
    "            self.vocab[token] = self.index\n",
    "            self.index += 1\n",
    "        \n",
    "        for k, v in self.vocab.items():\n",
    "            self.reverse_vocab[v] = k\n",
    "            \n",
    "        self.vocab_size = len(self.vocab)\n",
    "    \n",
    "    def fit_text(self, text):\n",
    "        for word in text.split():\n",
    "            if word not in self.vocab:\n",
    "                self.vocab[word] = self.index\n",
    "                self.reverse_vocab[self.index] = word\n",
    "                self.index += 1\n",
    "                self.vocab_size += 1\n",
    "                \n",
    "                if self.index >= self.vocab_size:\n",
    "                    break\n",
    "                \n",
    "    def fit_corpus(self, text):\n",
    "        for text in text:\n",
    "            self.fit_text(text)\n",
    "    \n",
    "    def encode(self, text, add_sos=False, get_mask=False):\n",
    "        seq = []\n",
    "        for word in text.split():\n",
    "            if word in self.vocab:\n",
    "                seq.append(self.vocab[word])\n",
    "            else:\n",
    "                seq.append(self.vocab['<UNK>'])\n",
    "                \n",
    "        if len(seq) > self.max_seq_len:\n",
    "            mask = [1] * self.max_seq_len\n",
    "            seq = seq[:self.max_seq_len]\n",
    "        else:\n",
    "            mask = [1] * len(seq) + [0] * (self.max_seq_len - len(seq))\n",
    "            seq = seq + [self.vocab['<PAD>']] * (self.max_seq_len - len(seq))\n",
    "            \n",
    "        if add_sos:\n",
    "            seq = [self.vocab['<SOS>']] + seq[:-1]\n",
    "            mask = [1] + mask[:-1]\n",
    "        \n",
    "        if get_mask:\n",
    "            return torch.tensor(seq), torch.tensor(mask)\n",
    "        else:\n",
    "            return torch.tensor(seq)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.vocab)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.vocab[key]\n",
    "    \n",
    "    def decode(self, seq):\n",
    "        if type(seq) == torch.Tensor:\n",
    "            seq = seq.numpy()\n",
    "        return ' '.join([self.reverse_vocab[i] for i in seq if i != self.vocab['<PAD>']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<UNK>': 1, '<SOS>': 2, '<EOS>': 3}\n",
      "{0: '<PAD>', 1: '<UNK>', 2: '<SOS>', 3: '<EOS>'}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = CustomTokenizer(VOCAB_SIZE, MAX_SEQ_LEN)\n",
    "\n",
    "tokenizer.fit_corpus([standardization(open(path, 'r', encoding='utf8').read()) for path in file_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded text: tensor([    2,     6,    13,    19,  3385, 10120,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Mask: tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "text = 'this is a test sentence'\n",
    "\n",
    "encoded_text, mask = tokenizer.encode(text, add_sos=True, get_mask=True)\n",
    "print(f'Encoded text: {encoded_text}')\n",
    "print(f'Mask: {mask}')\n",
    "print(f'Encoded text: {tokenizer.decode(encoded_text)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_lm_input_labels(text):\n",
    "    input_ids, input_mask = tokenizer.encode(text, add_sos=True, get_mask=True)\n",
    "    labels, label_mask = tokenizer.encode(text, add_sos=False, get_mask=True)\n",
    "    return input_ids, input_mask, labels, label_mask\n",
    "\n",
    "class TextGenerationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_paths, seq_len, tokenizer, standardize=True, get_mask=True):\n",
    "        self.file_paths = file_paths\n",
    "        self.seq_len = seq_len\n",
    "        self.tokenizer = tokenizer\n",
    "        self.standardize = standardize\n",
    "        self.get_mask = get_mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with open(self.file_paths[idx], 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            \n",
    "        if self.standardize:\n",
    "            text = standardization(text)\n",
    "        \n",
    "        input_ids, input_mask, labels, label_mask = prepare_lm_input_labels(text)\n",
    "        sample = {\n",
    "            'input_ids': input_ids,\n",
    "            'target_ids': labels,\n",
    "        }\n",
    "        if self.get_mask:\n",
    "            sample['input_mask'] = input_mask\n",
    "            sample['target_mask'] = label_mask\n",
    "            \n",
    "        return sample\n",
    "        \n",
    "        # return self.tokenizer.encode(text, add_sos=True, get_mask=self.get_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TextGenerationDataset(file_path, MAX_SEQ_LEN, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded input: tensor([    2,   203,   115,    81,   270,    93,   564,    19,  3508,  2271,\n",
      "          150,   291,   370,   435, 15969,    13,   444,  6316,   437,   947,\n",
      "          856,    19,  2996,    83,   408,    49, 15880,  3359,   164,  5521,\n",
      "           10,     4,    13,    17,   236,   392,   291,   936,   437,    10,\n",
      "          209,     9,  5412,    70, 15847, 14932,  2213,    19,  2683,   292,\n",
      "         5989,   115,   982,   291,    19,    63,  1108,  2700,    93,   249,\n",
      "           86,    22,    19, 16002,  2083,  2700,  2458,  5518,    19,   615,\n",
      "          151,   437,    10, 14273,   331,  2458,   183,     1,   233,    10])\n",
      "Encoded target: tensor([  203,   115,    81,   270,    93,   564,    19,  3508,  2271,   150,\n",
      "          291,   370,   435, 15969,    13,   444,  6316,   437,   947,   856,\n",
      "           19,  2996,    83,   408,    49, 15880,  3359,   164,  5521,    10,\n",
      "            4,    13,    17,   236,   392,   291,   936,   437,    10,   209,\n",
      "            9,  5412,    70, 15847, 14932,  2213,    19,  2683,   292,  5989,\n",
      "          115,   982,   291,    19,    63,  1108,  2700,    93,   249,    86,\n",
      "           22,    19, 16002,  2083,  2700,  2458,  5518,    19,   615,   151,\n",
      "          437,    10, 14273,   331,  2458,   183,     1,   233,    10,   630])\n",
      "Decoded input: <SOS> oh its so cool to watch a silent classic once in while director vidor is simply delightful and even makes a lengthy at least for 1928 cameo as himself the story is about having success in life and the way it changes you marion davies plays a girl that leaves its friends in a little comedy studio to be part of a larger drama studio she becomes a big star and the consequences are she really <UNK> from the\n"
     ]
    }
   ],
   "source": [
    "idx = random.randint(0, len(dataset))\n",
    "\n",
    "sample = dataset[idx]\n",
    "encoded_input = sample['input_ids']\n",
    "encoded_target = sample['target_ids']\n",
    "print(f'Encoded input: {encoded_input}')\n",
    "print(f'Encoded target: {encoded_target}')\n",
    "print(f'Decoded input: {tokenizer.decode(encoded_input)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - Transformer Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_casual_attention_mask(batch_size, seq_len, n_dest, n_src, dtype=torch.float32):\n",
    "    \"\"\"Generate a causal mask for the decoder\n",
    "\n",
    "    Args:\n",
    "        batch_size (int): batch size\n",
    "        seq_len (int): sequence length\n",
    "        n_dest (int): number of destination tokens\n",
    "        n_src (int): number of source tokens\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: causal mask\n",
    "    \"\"\"\n",
    "    i = torch.arange(n_dest)[:, None]\n",
    "    j = torch.arange(n_src)\n",
    "    m = i >= j - n_src + n_dest\n",
    "    mask = m.to(dtype)\n",
    "    mask = mask.reshape(1, n_dest, n_src)\n",
    "    mult = torch.tensor([batch_size, 1, 1])\n",
    "    return mask.repeat(mult.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "\n",
       "        [[1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_casual_attention_mask(2, 10, 5, 10, torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embedding_dim, n_heads, ff_dim, dropout=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        \n",
    "        self.multi_head_attn = nn.MultiheadAttention(\n",
    "            embedding_dim, n_heads, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, embedding_dim)\n",
    "        )\n",
    "        \n",
    "        self.layer_norm1 = nn.LayerNorm(embedding_dim)\n",
    "        self.layer_norm2 = nn.LayerNorm(embedding_dim)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        batch_size, seq_len, d_model = x.shape\n",
    "        casual_mask = get_casual_attention_mask(batch_size, seq_len, seq_len, seq_len, x.dtype)\n",
    "        \n",
    "        # make a mask for padding tokens\n",
    "        key_padding_mask = (1 - mask).bool() if mask is not None else None\n",
    "        context_vector, _ = self.multi_head_attn(\n",
    "            x, x, x,\n",
    "            key_padding_mask=key_padding_mask,\n",
    "            # attn_mask=casual_mask\n",
    "        )\n",
    "        context_vector = self.dropout1(context_vector)\n",
    "        out1 = self.layer_norm1(x + context_vector)\n",
    "        \n",
    "        ffn_out = self.ffn(out1)\n",
    "        ffn_out = self.dropout2(ffn_out)\n",
    "        \n",
    "        return self.layer_norm2(out1 + ffn_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionalEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, max_seq_len, embedding_dim):\n",
    "        super(TokenAndPositionalEmbedding, self).__init__()\n",
    "        \n",
    "        self.token_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_seq_len, embedding_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.shape\n",
    "        positions = torch.arange(0, seq_len).expand(batch_size, seq_len).to(x.device)\n",
    "        return self.token_embedding(x) + self.pos_embedding(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorModel(nn.Module):\n",
    "    def __init__(\n",
    "        self, vocab_size, max_seq_len, embedding_dim, n_heads, ff_dim, n_layers, dropout=0.1\n",
    "    ):\n",
    "        super(GeneratorModel, self).__init__()\n",
    "        \n",
    "        self.embedding = TokenAndPositionalEmbedding(vocab_size, max_seq_len, embedding_dim)\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerBlock(embedding_dim, n_heads, ff_dim, dropout) for _ in range(n_layers)\n",
    "        ])\n",
    "        self.fc = nn.Linear(embedding_dim, vocab_size)\n",
    "        \n",
    "        self.apply(init_weights)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.embedding(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.fc(x)\n",
    "    \n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.kaiming_normal_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "    elif isinstance(m, nn.Embedding):\n",
    "        torch.nn.init.normal_(m.weight, std=0.02)\n",
    "    elif isinstance(m, nn.LayerNorm):\n",
    "        torch.nn.init.normal_(m.weight, std=0.02)\n",
    "        torch.nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    avg_loss = 0\n",
    "    pbar = tqdm(data_loader)\n",
    "    for batch in pbar:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        target_ids = batch['target_ids'].to(device)\n",
    "        input_mask = batch['input_mask'].to(device)\n",
    "        target_mask = batch['target_mask'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(input_ids, input_mask)\n",
    "        output = output.reshape(-1, output.shape[-1])\n",
    "        target_ids = target_ids.reshape(-1)\n",
    "        target_mask = target_mask.reshape(-1)\n",
    "        \n",
    "        loss = criterion(output, target_ids)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        avg_loss = (0.99 * avg_loss + 0.01 * loss.item()) / (1 - 0.99 ** (len(losses) + 1))\n",
    "        pbar.set_description(f'Loss: {loss.item():.4f}')\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc29d9892b0a42bc9a8ce3850a4612bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(EPOCHS):\n\u001b[0;32m     31\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTraining Epoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m02\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m     train_loss \u001b[39m=\u001b[39m train(model, dataloader, optimizer, critetion, DEVICE)\n\u001b[0;32m     33\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m02\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Train Loss: \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     34\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m#\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m)\n",
      "Cell \u001b[1;32mIn[38], line 20\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, data_loader, optimizer, criterion, device)\u001b[0m\n\u001b[0;32m     18\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     19\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m---> 20\u001b[0m     losses\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39;49mitem())\n\u001b[0;32m     22\u001b[0m     pbar\u001b[39m.\u001b[39mset_description(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLoss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m.\u001b[39mitem()\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmean(losses)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = TextGenerationDataset(file_path, MAX_SEQ_LEN, tokenizer)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "model = GeneratorModel(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    max_seq_len=MAX_SEQ_LEN,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    n_heads=N_HEADS,\n",
    "    ff_dim=FF_DIM,\n",
    "    n_layers=N_LAYERS,\n",
    "    dropout=DROP_OUT\n",
    ")\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "critetion = nn.CrossEntropyLoss(ignore_index=tokenizer['<PAD>'])\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Training Epoch: {epoch+1:02}')\n",
    "    train_loss = train(model, dataloader, optimizer, critetion, DEVICE)\n",
    "    print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.4f}')\n",
    "    print(\"#\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from(logits, top_k=10):\n",
    "    logits, indices = torch.topk(logits, top_k)\n",
    "    indices = np.asarray(indices).astype(np.int32)\n",
    "    preds = torch.softmax(logits, dim=-1).numpy()\n",
    "    preds = np.asarray(preds).astype(np.float32)\n",
    "    return np.random.choice(indices, p=preds)\n",
    "\n",
    "def generate(start_tokens, max_generated_tokens):\n",
    "    start_tokens = [_ for _ in start_tokens]\n",
    "    num_tokens_generated_local = 0\n",
    "    tokens_generated = []\n",
    "    max_generated_tokens \n",
    "    while num_tokens_generated_local <= max_generated_tokens:\n",
    "        pad_len = MAX_SEQ_LEN - len(start_tokens)\n",
    "        sample_index = len(start_tokens) - 1\n",
    "        if pad_len > 0:\n",
    "            x = start_tokens + [0] * pad_len\n",
    "        else:\n",
    "            x = start_tokens\n",
    "        x = torch.tensor(x).unsqueeze(0).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            y = model(x)\n",
    "            y = y.cpu()\n",
    "            \n",
    "        sample_token = sample_from(y[0][sample_index])\n",
    "        \n",
    "        if sample_token == tokenizer['<EOS>']:\n",
    "            break\n",
    "        \n",
    "        tokens_generated.append(sample_token)\n",
    "        start_tokens.append(sample_token)\n",
    "        num_tokens_generated_local = len(tokens_generated)\n",
    "        \n",
    "    txt = tokenizer.decode(tokens_generated)\n",
    "    return txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: this movie is\n",
      "Generated Text: a movie the in the to the to and of <UNK> the is to a of <UNK> to to the <UNK> a to this movie i is a the the in\n"
     ]
    }
   ],
   "source": [
    "start_prompt = \"this movie is\"\n",
    "start_tokens = tokenizer.encode(start_prompt)[:len(start_prompt.split())]\n",
    "num_tokens_generated = 30\n",
    "self_max_tokens = 30\n",
    "\n",
    "generated_text = generate(start_tokens, max_generated_tokens=self_max_tokens)\n",
    "\n",
    "print(f'Prompt: {start_prompt}')\n",
    "print(f'Generated Text: {generated_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4b1d2403d5bedfc2b499b2d1212ae0437b5f8ebf43026ed45c1b9608ddeb20c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
