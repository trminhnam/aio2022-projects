VOCAB_SIZE = 20000
MAX_SEQ_LEN = 80

EPOCHS = 30
BATCH_SIZE = 16
LEARNING_RATE = 3e-5

EMBEDDING_DIM = 256
N_HEADS = 8
FF_DIM = 256
N_LAYERS = 1
DROP_OUT = 0.1

DATASET_DIR = "aclImdb"
OUTPUT_DIR = "output"
MODEL_PATH = None
SAVE_MODEL_EVERY = 5

TOKENIZER_SAVE_PATH = "tokenizer.json"
PRETRAINED_PATH = "output/model_5.pt"